ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
[2025-07-22 05:03:07,090] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-07-22 05:03:09,043] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
W0722 05:03:09.771000 1835479 site-packages/torch/distributed/run.py:766] 
W0722 05:03:09.771000 1835479 site-packages/torch/distributed/run.py:766] *****************************************
W0722 05:03:09.771000 1835479 site-packages/torch/distributed/run.py:766] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0722 05:03:09.771000 1835479 site-packages/torch/distributed/run.py:766] *****************************************
/data/kuimou/miniconda3/envs/openANT_test/lib/python3.10/site-packages/accelerate/utils/dataclasses.py:1268: UserWarning: DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.
  warnings.warn("DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.")
/data/kuimou/miniconda3/envs/openANT_test/lib/python3.10/site-packages/accelerate/utils/dataclasses.py:1268: UserWarning: DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.
  warnings.warn("DeepSpeed Zero3 Init flag is only applicable for ZeRO Stage 3. Setting it to False.")
[2025-07-22 05:03:16,777] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-07-22 05:03:16,807] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-07-22 05:03:18,452] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-07-22 05:03:18,479] [INFO] [comm.py:676:init_distributed] cdb=None
[2025-07-22 05:03:18,479] [INFO] [comm.py:707:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-07-22 05:03:18,551] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-07-22 05:03:18,580] [INFO] [comm.py:676:init_distributed] cdb=None
------------ Options -------------
abstractor: True
base_dim: 512
batch_size: 64
batch_size_eval: 32
beta_schedule: linear
cfg_scale: 2.5
cfg_scheduler_type: none
checkpoints_dir: ./checkpoints
clip_grad_norm: 1
cond_mask_prob: 0.1
continue_ckpt: latest.tar
dataset_name: t2m
decay_rate: 0.9
diffuser_name: dpmsolver
diffusion_steps: 1000
dim_mults: [2, 2, 2, 2]
disable_sta: False
diversity_times: 300
dropout: 0.1
enable_cfg_scheduler: False
enable_trace: False
eval_meta_dir: ./data
evaluator_dir: ./data/pretrained_models
evl_mode: fid
feat_bias: 5
glove_dir: ./data/glove
is_continue: False
laten_size: 77
latent_dim: 512
log_every: 500
lr: 0.0001
mm_num_repeats: 30
mm_num_samples: 100
mm_num_times: 10
model_ema: False
model_ema_decay: 0.9999
model_ema_steps: 32
name: t2m
no_adagn: False
no_eff: False
no_ema: False
no_fp16: False
num_inference_steps: 10
num_layers: 8
num_train_steps: 200000
opt_path: 
prediction_type: sample
replication_times: 20
save_interval: 5000
seed: 0
text_encoder_type: t5
text_latent_dim: 256
time_dim: 512
update_lr_steps: 5000
weight_decay: 0.01
which_ckpt: latest_120000
-------------- End ----------------

 Loading train mode HumanML3D train dataset ...
  0%|          | 0/23384 [00:00<?, ?it/s]  1%|          | 291/23384 [00:00<00:07, 2901.92it/s]  2%|▏         | 582/23384 [00:00<00:07, 2858.77it/s]  4%|▎         | 875/23384 [00:00<00:07, 2890.68it/s]  5%|▌         | 1173/23384 [00:00<00:07, 2923.90it/s]  6%|▋         | 1466/23384 [00:00<00:07, 2923.33it/s]  8%|▊         | 1759/23384 [00:00<00:07, 2916.30it/s]  9%|▉         | 2051/23384 [00:00<00:07, 2894.52it/s] 10%|█         | 2347/23384 [00:00<00:07, 2914.44it/s] 11%|█▏        | 2641/23384 [00:00<00:07, 2921.50it/s] 13%|█▎        | 2935/23384 [00:01<00:06, 2926.47it/s] 14%|█▍        | 3230/23384 [00:01<00:06, 2930.76it/s] 15%|█▌        | 3524/23384 [00:01<00:06, 2932.29it/s] 16%|█▋        | 3821/23384 [00:01<00:06, 2940.55it/s] 18%|█▊        | 4118/23384 [00:01<00:06, 2947.57it/s] 19%|█▉        | 4415/23384 [00:01<00:06, 2952.31it/s] 20%|██        | 4711/23384 [00:01<00:06, 2938.15it/s] 21%|██▏       | 5005/23384 [00:01<00:06, 2936.80it/s] 23%|██▎       | 5299/23384 [00:01<00:06, 2934.55it/s] 24%|██▍       | 5593/23384 [00:01<00:06, 2935.42it/s] 25%|██▌       | 5887/23384 [00:02<00:06, 2914.87it/s] 26%|██▋       | 6180/23384 [00:02<00:05, 2918.74it/s] 28%|██▊       | 6472/23384 [00:02<00:05, 2911.06it/s] 29%|██▉       | 6773/23384 [00:02<00:05, 2938.76it/s] 30%|███       | 7076/23384 [00:02<00:05, 2963.74it/s] 32%|███▏      | 7373/23384 [00:02<00:05, 2964.76it/s] 33%|███▎      | 7670/23384 [00:02<00:05, 2959.32it/s] 34%|███▍      | 7970/23384 [00:02<00:05, 2970.64it/s] 35%|███▌      | 8269/23384 [00:02<00:05, 2973.83it/s] 37%|███▋      | 8571/23384 [00:02<00:04, 2984.52it/s] 38%|███▊      | 8879/23384 [00:03<00:04, 3009.85it/s] 39%|███▉      | 9180/23384 [00:03<00:04, 2988.97it/s] 41%|████      | 9479/23384 [00:03<00:08, 1646.39it/s] 42%|████▏     | 9769/23384 [00:03<00:07, 1884.10it/s] 43%|████▎     | 10067/23384 [00:03<00:06, 2117.43it/s] 44%|████▍     | 10356/23384 [00:03<00:05, 2296.90it/s] 45%|████▌     | 10628/23384 [00:03<00:05, 2355.81it/s] 47%|████▋     | 10921/23384 [00:04<00:04, 2504.18it/s] 48%|████▊     | 11213/23384 [00:04<00:04, 2616.51it/s] 49%|████▉     | 11499/23384 [00:04<00:04, 2682.49it/s] 50%|█████     | 11789/23384 [00:04<00:04, 2743.75it/s] 52%|█████▏    | 12082/23384 [00:04<00:04, 2796.73it/s] 53%|█████▎    | 12373/23384 [00:04<00:03, 2827.62it/s] 54%|█████▍    | 12674/23384 [00:04<00:03, 2878.98it/s] 55%|█████▌    | 12976/23384 [00:04<00:03, 2918.67it/s] 57%|█████▋    | 13271/23384 [00:04<00:03, 2910.37it/s] 58%|█████▊    | 13564/23384 [00:04<00:03, 2912.75it/s] 59%|█████▉    | 13861/23384 [00:05<00:03, 2928.48it/s] 61%|██████    | 14156/23384 [00:05<00:03, 2932.38it/s] 62%|██████▏   | 14450/23384 [00:05<00:03, 2929.98it/s] 63%|██████▎   | 14773/23384 [00:05<00:02, 3017.01it/s] 65%|██████▍   | 15163/23384 [00:05<00:02, 3280.44it/s] 67%|██████▋   | 15557/23384 [00:05<00:02, 3475.09it/s] 68%|██████▊   | 15955/23384 [00:05<00:02, 3624.56it/s] 70%|██████▉   | 16332/23384 [00:05<00:01, 3667.55it/s] 72%|███████▏  | 16720/23384 [00:05<00:01, 3729.32it/s] 73%|███████▎  | 17094/23384 [00:05<00:01, 3709.41it/s] 75%|███████▍  | 17503/23384 [00:06<00:01, 3821.89it/s] 77%|███████▋  | 17897/23384 [00:06<00:01, 3854.25it/s] 78%|███████▊  | 18283/23384 [00:06<00:01, 3802.23it/s] 80%|███████▉  | 18671/23384 [00:06<00:01, 3822.65it/s] 82%|████████▏ | 19070/23384 [00:06<00:01, 3870.78it/s] 83%|████████▎ | 19466/23384 [00:06<00:01, 3894.44it/s] 85%|████████▍ | 19873/23384 [00:06<00:00, 3945.63it/s] 87%|████████▋ | 20268/23384 [00:06<00:00, 3889.48it/s] 88%|████████▊ | 20678/23384 [00:06<00:00, 3951.02it/s] 90%|█████████ | 21074/23384 [00:06<00:00, 3838.22it/s] 92%|█████████▏| 21472/23384 [00:07<00:00, 3879.39it/s] 94%|█████████▎| 21880/23384 [00:07<00:00, 3936.91it/s] 95%|█████████▌| 22275/23384 [00:07<00:00, 3936.45it/s] 97%|█████████▋| 22681/23384 [00:07<00:00, 3971.51it/s] 99%|█████████▊| 23079/23384 [00:07<00:00, 3958.16it/s]100%|██████████| 23384/23384 [00:07<00:00, 3113.67it/s]
Completing loading t2m dataset

Initializing model ...
Namespace(name='t2m', dataset_name='t2m', feat_bias=5, checkpoints_dir='./checkpoints', log_every=500, save_interval=5000, num_layers=8, latent_dim=512, text_latent_dim=256, time_dim=512, base_dim=512, dim_mults=[2, 2, 2, 2], no_eff=False, no_adagn=False, diffusion_steps=1000, prediction_type='sample', text_encoder_type='t5', abstractor=True, disable_sta=False, laten_size=77, dropout=0.1, seed=0, num_train_steps=200000, lr=0.0001, decay_rate=0.9, update_lr_steps=5000, cond_mask_prob=0.1, clip_grad_norm=1, weight_decay=0.01, batch_size=64, beta_schedule='linear', enable_trace=False, is_continue=False, continue_ckpt='latest.tar', opt_path='', which_ckpt='latest_120000', evaluator_dir='./data/pretrained_models', eval_meta_dir='./data', glove_dir='./data/glove', num_inference_steps=10, diffuser_name='dpmsolver', no_ema=False, no_fp16=False, enable_cfg_scheduler=False, cfg_scheduler_type='none', replication_times=20, batch_size_eval=32, diversity_times=300, mm_num_samples=100, mm_num_repeats=30, mm_num_times=10, evl_mode='fid', cfg_scale=2.5, model_ema=False, model_ema_steps=32, model_ema_decay=0.9999, unit_length=4, max_text_len=20, text_enc_mod='bigru', estimator_mod='bigru', dim_text_hidden=512, dim_att_vec=512, dim_z=128, dim_movement_enc_hidden=512, dim_movement_dec_hidden=512, dim_movement_latent=512, dim_word=300, dim_pos_ohot=15, dim_motion_hidden=1024, dim_coemb_hidden=512, joints_num=22, dim_pose=263, max_motion_length=196, radius=4, fps=20, device=device(type='cuda', index=0), is_train=True, save_root='./checkpoints/t2m/t2m', model_dir='./checkpoints/t2m/t2m/model', meta_dir='./checkpoints/t2m/t2m/meta')
Creating UNet with text encoder: 't5'
Loading T5 model from: ./T5
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 31.94it/s]
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Namespace(name='t2m', dataset_name='t2m', feat_bias=5, checkpoints_dir='./checkpoints', log_every=500, save_interval=5000, num_layers=8, latent_dim=512, text_latent_dim=256, time_dim=512, base_dim=512, dim_mults=[2, 2, 2, 2], no_eff=False, no_adagn=False, diffusion_steps=1000, prediction_type='sample', text_encoder_type='t5', abstractor=True, disable_sta=False, laten_size=77, dropout=0.1, seed=0, num_train_steps=200000, lr=0.0001, decay_rate=0.9, update_lr_steps=5000, cond_mask_prob=0.1, clip_grad_norm=1, weight_decay=0.01, batch_size=64, beta_schedule='linear', enable_trace=False, is_continue=False, continue_ckpt='latest.tar', opt_path='', which_ckpt='latest_120000', evaluator_dir='./data/pretrained_models', eval_meta_dir='./data', glove_dir='./data/glove', num_inference_steps=10, diffuser_name='dpmsolver', no_ema=False, no_fp16=False, enable_cfg_scheduler=False, cfg_scheduler_type='none', replication_times=20, batch_size_eval=32, diversity_times=300, mm_num_samples=100, mm_num_repeats=30, mm_num_times=10, evl_mode='fid', cfg_scale=2.5, model_ema=False, model_ema_steps=32, model_ema_decay=0.9999, unit_length=4, max_text_len=20, text_enc_mod='bigru', estimator_mod='bigru', dim_text_hidden=512, dim_att_vec=512, dim_z=128, dim_movement_enc_hidden=512, dim_movement_dec_hidden=512, dim_movement_latent=512, dim_word=300, dim_pos_ohot=15, dim_motion_hidden=1024, dim_coemb_hidden=512, joints_num=22, dim_pose=263, max_motion_length=196, radius=4, fps=20, device=device(type='cuda', index=1), is_train=True, save_root='./checkpoints/t2m/t2m', model_dir='./checkpoints/t2m/t2m/model', meta_dir='./checkpoints/t2m/t2m/meta')
Creating UNet with text encoder: 't5'
Loading T5 model from: ./T5
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 19.93it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 19.87it/s]
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Building STA connector.
[CondUnet1D] Dims: [263, 1024, 1024, 1024, 1024], Multipliers: [2, 2, 2, 2]
Building STA connector.
[CondUnet1D] Dims: [263, 1024, 1024, 1024, 1024], Multipliers: [2, 2, 2, 2]
T2M-Unet model created successfully.
Finish building Model.

Diffusion_config:
 FrozenDict([('num_train_timesteps', 1000), ('beta_start', 0.0001), ('beta_end', 0.02), ('beta_schedule', 'linear'), ('trained_betas', None), ('variance_type', 'fixed_small'), ('clip_sample', False), ('prediction_type', 'sample'), ('thresholding', False), ('dynamic_thresholding_ratio', 0.995), ('clip_sample_range', 1.0), ('sample_max_value', 1.0), ('timestep_spacing', 'leading'), ('steps_offset', 0), ('rescale_betas_zero_snr', False), ('_use_default_values', ['thresholding', 'sample_max_value', 'steps_offset', 'timestep_spacing', 'trained_betas', 'rescale_betas_zero_snr', 'beta_end', 'clip_sample_range', 'beta_start', 'dynamic_thresholding_ratio'])])
T2M-Unet model created successfully.
wandb: Currently logged in as: ccs_covenant (ccs_covenant-hong-kong-university-of-science-and-technology) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[rank1]:[W722 05:03:30.731524384 ProcessGroupNCCL.cpp:4715] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
wandb: Tracking run with wandb version 0.21.0
wandb: Run data is saved locally in /data/kuimou/openANT/wandb/run-20250722_050330-ccsiogyb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run t2m_20250722-05_8c8630
wandb: ⭐️ View project at https://wandb.ai/ccs_covenant-hong-kong-university-of-science-and-technology/t2m
wandb: 🚀 View run at https://wandb.ai/ccs_covenant-hong-kong-university-of-science-and-technology/t2m/runs/ccsiogyb
Start experiment: 2025-07-22_05:03:31
[rank0]:[W722 05:03:31.996543752 ProcessGroupNCCL.cpp:4715] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
Setting up evaluation components...

Loading Evaluation Model Wrapper (Epoch 28) Completed!!

 Loading gt_eval mode HumanML3D dataset ...
./data/t2m_std.npy
  0%|          | 0/1460 [00:00<?, ?it/s] 28%|██▊       | 411/1460 [00:00<00:00, 4100.94it/s] 56%|█████▋    | 822/1460 [00:00<00:00, 1482.96it/s] 86%|████████▋ | 1260/1460 [00:00<00:00, 2156.77it/s]100%|██████████| 1460/1460 [00:00<00:00, 2258.75it/s]
Completing loading t2m dataset

 Loading eval mode HumanML3D dataset ...
./checkpoints/t2m/t2m/meta/std.npy
  0%|          | 0/1460 [00:00<?, ?it/s] 28%|██▊       | 412/1460 [00:00<00:00, 4118.97it/s] 56%|█████▋    | 824/1460 [00:00<00:00, 3439.09it/s][rank1]: Traceback (most recent call last):
[rank1]:   File "/data/kuimou/miniconda3/envs/openANT_test/lib/python3.10/runpy.py", line 196, in _run_module_as_main
[rank1]:     return _run_code(code, main_globals, None,
[rank1]:   File "/data/kuimou/miniconda3/envs/openANT_test/lib/python3.10/runpy.py", line 86, in _run_code
[rank1]:     exec(code, run_globals)
[rank1]:   File "/data/kuimou/openANT/scripts/train.py", line 73, in <module>
[rank1]:     trainer.train(train_datasetloader)
[rank1]:   File "/data/kuimou/openANT/trainers/ddpm_trainer.py", line 275, in train
[rank1]:     self.forward(batch_data)
[rank1]:   File "/data/kuimou/openANT/trainers/ddpm_trainer.py", line 92, in forward
[rank1]:     self.prediction = self.model(x_t, t, text=caption)
[rank1]:   File "/data/kuimou/miniconda3/envs/openANT_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/data/kuimou/miniconda3/envs/openANT_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/data/kuimou/openANT/models/t2m_unet.py", line 138, in forward
[rank1]:     output_padded = self.unet(
[rank1]:   File "/data/kuimou/miniconda3/envs/openANT_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/data/kuimou/miniconda3/envs/openANT_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/data/kuimou/openANT/models/submodules/unet_1d.py", line 71, in forward
[rank1]:     x = block1(x, temb, cond, cond_indices)
[rank1]:   File "/data/kuimou/miniconda3/envs/openANT_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/data/kuimou/miniconda3/envs/openANT_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/data/kuimou/openANT/models/submodules/cond_conv_block.py", line 37, in forward
[rank1]:     x = self.conv1d(x, t)
[rank1]:   File "/data/kuimou/miniconda3/envs/openANT_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/data/kuimou/miniconda3/envs/openANT_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/data/kuimou/openANT/models/submodules/residual_block.py", line 77, in forward
[rank1]:     out = self.blocks[0](out, scale, shift)
[rank1]:   File "/data/kuimou/miniconda3/envs/openANT_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/data/kuimou/miniconda3/envs/openANT_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/data/kuimou/openANT/models/submodules/basic_blocks.py", line 95, in forward
[rank1]:     x = self.block(x)
[rank1]:   File "/data/kuimou/miniconda3/envs/openANT_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/data/kuimou/miniconda3/envs/openANT_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/data/kuimou/miniconda3/envs/openANT_test/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 375, in forward
[rank1]:     return self._conv_forward(input, self.weight, self.bias)
[rank1]:   File "/data/kuimou/miniconda3/envs/openANT_test/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 370, in _conv_forward
[rank1]:     return F.conv1d(
[rank1]: RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor
 80%|████████  | 1175/1460 [00:00<00:00, 3296.95it/s]100%|██████████| 1460/1460 [00:00<00:00, 3323.35it/s]
Completing loading t2m dataset
Evaluation components are ready.
[2025-07-22 05:03:33,412] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed info: version=0.17.2, git-hash=unknown, git-branch=unknown
[2025-07-22 05:03:33,413] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 2
[2025-07-22 05:03:33,432] [INFO] [engine.py:1339:_configure_distributed_model] ********** distributed groups summary **********
	 self.dp_world_size=2
	 self.mp_world_size=1
	 self.seq_dp_world_size=2
	 self.sequence_parallel_size=1
***********************************************
W0722 05:03:36.365000 1835479 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 1835804 closing signal SIGTERM
E0722 05:03:36.983000 1835479 site-packages/torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 1 (pid: 1835805) of binary: /data/kuimou/miniconda3/envs/openANT_test/bin/python3.10
Traceback (most recent call last):
  File "/data/kuimou/miniconda3/envs/openANT_test/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/data/kuimou/miniconda3/envs/openANT_test/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
    args.func(args)
  File "/data/kuimou/miniconda3/envs/openANT_test/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1184, in launch_command
    deepspeed_launcher(args)
  File "/data/kuimou/miniconda3/envs/openANT_test/lib/python3.10/site-packages/accelerate/commands/launch.py", line 868, in deepspeed_launcher
    distrib_run.run(args)
  File "/data/kuimou/miniconda3/envs/openANT_test/lib/python3.10/site-packages/torch/distributed/run.py", line 883, in run
    elastic_launch(
  File "/data/kuimou/miniconda3/envs/openANT_test/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 139, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/data/kuimou/miniconda3/envs/openANT_test/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 270, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
scripts.train FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-07-22_05:03:36
  host      : bld
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 1835805)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
